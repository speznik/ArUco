{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-contrib-python-headless"
      ],
      "metadata": {
        "id": "RNQF-DXn6INZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def preprocess_image(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 125, 255, cv2.THRESH_BINARY)\n",
        "    return thresh\n",
        "\n",
        "def detect_potential_markers(thresh):\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    potential_markers = []\n",
        "    for contour in contours:\n",
        "        potential_markers.append(contour)\n",
        "    return potential_markers\n",
        "\n",
        "def verify_and_refine_markers(potential_markers, gray_image):\n",
        "    verified_markers = []\n",
        "    for marker in potential_markers:\n",
        "        if verify_marker(marker, gray_image):\n",
        "            refined_marker = refine_corners(marker, gray_image)\n",
        "            verified_markers.append(refined_marker)\n",
        "    return verified_markers\n",
        "\n",
        "def verify_marker(marker, gray_image):\n",
        "    pass\n",
        "\n",
        "def detect_aruco_markers(image):\n",
        "    preprocessed = preprocess_image(image)\n",
        "    potential_markers = detect_potential_markers(preprocessed)\n",
        "    verified_markers = verify_and_refine_markers(potential_markers, preprocessed)\n",
        "    decoded_markers = [decode_marker(marker, preprocessed) for marker in verified_markers]\n",
        "    return decoded_markers\n",
        "\n",
        "image = cv2.imread(\"test.jpg\")\n",
        "detected_markers = detect_aruco_markers(image)\n"
      ],
      "metadata": {
        "id": "-nzGhYUKHR1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                   cv2.THRESH_BINARY_INV, 11, 2)\n",
        "\n",
        "    return thresh\n",
        "\n",
        "thresh_image = preprocess_image('test.jpg')\n",
        "\n",
        "cv2_imshow(thresh_image)\n",
        "\n"
      ],
      "metadata": {
        "id": "QmOqydWiHRzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_potential_markers(thresh_image):\n",
        "    contours, _ = cv2.findContours(thresh_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    potential_markers = []\n",
        "\n",
        "    for contour in contours:\n",
        "        perimeter = cv2.arcLength(contour, True)\n",
        "        approx = cv2.approxPolyDP(contour, 0.04 * perimeter, True)\n",
        "        if len(approx) == 4:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if minimum_area_threshold < area < maximum_area_threshold:\n",
        "                potential_markers.append(approx)\n",
        "\n",
        "    return potential_markers\n",
        "\n",
        "image_resolution = (1390, 857)\n",
        "image_area = image_resolution[0] * image_resolution[1]\n",
        "\n",
        "min_area_percentage = 0.01\n",
        "max_area_percentage = 0.1\n",
        "\n",
        "minimum_area_threshold = min_area_percentage * image_area\n",
        "maximum_area_threshold = max_area_percentage * image_area\n",
        "\n",
        "thresh_image = preprocess_image('test.jpg')\n",
        "potential_markers = detect_potential_markers(thresh_image)\n",
        "\n",
        "for marker in potential_markers:\n",
        "    cv2.drawContours(thresh_image, [marker], -1, (255, 0, 0), 2)\n",
        "\n",
        "cv2_imshow(thresh_image)\n"
      ],
      "metadata": {
        "id": "5zHrXj8zIWpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def refine_corners(potential_markers, gray_image):\n",
        "    refined_markers = []\n",
        "    for marker in potential_markers:\n",
        "        sorted_corners = sort_corners(marker)\n",
        "        refined_markers.append(sorted_corners)\n",
        "    return refined_markers\n",
        "\n",
        "def sort_corners(corners):\n",
        "    center = np.mean(corners, axis=0)\n",
        "    sorted_corners = sorted(corners, key=lambda c: -np.arctan2(c[0][1] - center[0][1], c[0][0] - center[0][0]))\n",
        "\n",
        "    top_left = min(sorted_corners, key=lambda c: c[0][0] + c[0][1])\n",
        "    top_left_index = sorted_corners.index(top_left)\n",
        "    sorted_corners = sorted_corners[top_left_index:] + sorted_corners[:top_left_index]\n",
        "\n",
        "    return sorted_corners\n",
        "\n",
        "refined_markers = refine_corners(potential_markers, thresh_image)\n",
        "for marker in refined_markers:\n",
        "    cv2.polylines(thresh_image, [np.array(marker)], isClosed=True, color=(255, 0, 0), thickness=2)\n",
        "\n",
        "cv2_imshow(thresh_image)"
      ],
      "metadata": {
        "id": "pCp61k3jJcFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def refine_corners(potential_markers, gray_image):\n",
        "    refined_markers = []\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
        "\n",
        "    for contour in potential_markers:\n",
        "        corners = np.float32(contour).reshape(-1, 2)\n",
        "        cv2.cornerSubPix(gray_image, corners, (5, 5), (-1, -1), criteria)\n",
        "\n",
        "        refined_markers.append(corners)\n",
        "\n",
        "    return refined_markers\n",
        "\n",
        "gray_image = np.float32(thresh_image)\n",
        "\n",
        "refined_markers = refine_corners(potential_markers, gray_image)\n",
        "\n",
        "for marker in refined_markers:\n",
        "    marker = marker.reshape(-1, 1, 2)\n",
        "    cv2.polylines(thresh_image, [np.int32(marker)], True, (255, 0, 0), 2)\n",
        "\n",
        "cv2_imshow(thresh_image)"
      ],
      "metadata": {
        "id": "6rHzCUjGQr92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_marker(image, refined_markers):\n",
        "    decoded_markers = []\n",
        "    marker_side_length = 6\n",
        "    for corners in refined_markers:\n",
        "        source_points = np.array(corners, dtype='float32')\n",
        "        destination_points = np.array([[0, 0], [marker_side_length - 1, 0],\n",
        "                                       [marker_side_length - 1, marker_side_length - 1], [0, marker_side_length - 1]],\n",
        "                                       dtype='float32')\n",
        "\n",
        "        transform_matrix = cv2.getPerspectiveTransform(source_points, destination_points)\n",
        "        marker_image = cv2.warpPerspective(image, transform_matrix, (marker_side_length, marker_side_length))\n",
        "\n",
        "        _, binary_marker_image = cv2.threshold(marker_image, 125, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        id = decode_id_from_binary_image(binary_marker_image[1:-1, 1:-1])  # exclude the border\n",
        "\n",
        "        if id is not None:\n",
        "            decoded_markers.append((id, corners))\n",
        "\n",
        "    return decoded_markers\n",
        "\n",
        "def decode_id_from_binary_image(binary_image):\n",
        "    grid_size = 4\n",
        "    step = binary_image.shape[0] // grid_size\n",
        "    id_bits = []\n",
        "\n",
        "    for y in range(0, binary_image.shape[0], step):\n",
        "        for x in range(0, binary_image.shape[1], step):\n",
        "            cell = binary_image[y:y+step, x:x+step]\n",
        "            bit = int(np.mean(cell) > 127)\n",
        "            id_bits.append(bit)\n",
        "\n",
        "    id = bits_to_id(id_bits)\n",
        "    return id\n",
        "\n",
        "def bits_to_id(bits):\n",
        "    #DICT_5X5_250\n",
        "    pass\n",
        "\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "decoded_markers = decode_marker(gray_image, refined_markers)\n",
        "\n",
        "for id, corners in decoded_markers:\n",
        "    print(f\"Decoded marker ID: {id}\")\n",
        "    corners = np.int0(corners)\n",
        "    cv2.polylines(image, [corners], True, (0, 255, 0), 2)\n",
        "\n",
        "cv2_imshow(\"Decoded Markers\", image)\n"
      ],
      "metadata": {
        "id": "dMmMWbExRRjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    _, thresh = cv2.threshold(blurred, 125, 255, cv2.THRESH_BINARY_INV)\n",
        "    return thresh, gray\n",
        "\n",
        "def detect_potential_markers(thresh_image):\n",
        "    contours, _ = cv2.findContours(thresh_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    potential_markers = []\n",
        "    for contour in contours:\n",
        "        perimeter = cv2.arcLength(contour, True)\n",
        "        approx = cv2.approxPolyDP(contour, 0.04 * perimeter, True)\n",
        "        if len(approx) == 4:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if minimum_area_threshold < area < maximum_area_threshold:\n",
        "                potential_markers.append(approx)\n",
        "    return potential_markers\n",
        "\n",
        "def refine_corners(potential_markers, gray_image):\n",
        "    refined_markers = []\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
        "    for contour in potential_markers:\n",
        "        corners = np.float32(contour).reshape(-1, 2)\n",
        "        cv2.cornerSubPix(gray_image, corners, (5, 5), (-1, -1), criteria)\n",
        "        refined_markers.append(corners)\n",
        "    return refined_markers\n",
        "\n",
        "def decode_marker(gray_image, refined_markers):\n",
        "    decoded_markers = []\n",
        "    marker_side_length = 50\n",
        "\n",
        "    for corners in refined_markers:\n",
        "        source_points = corners.reshape(4, 2)\n",
        "        destination_points = np.array([[0, 0], [marker_side_length - 1, 0],\n",
        "                                       [marker_side_length - 1, marker_side_length - 1], [0, marker_side_length - 1]],\n",
        "                                       dtype=\"float32\")\n",
        "\n",
        "        transform_matrix = cv2.getPerspectiveTransform(source_points, destination_points)\n",
        "        marker_image = cv2.warpPerspective(gray_image, transform_matrix, (marker_side_length, marker_side_length))\n",
        "\n",
        "        _, binary_marker_image = cv2.threshold(marker_image, 125, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        id_bits = extract_id_from_image(binary_marker_image[4:-4, 4:-4], grid_size=4)\n",
        "        marker_id = bits_to_id(id_bits)\n",
        "        if marker_id is not None:\n",
        "            decoded_markers.append((marker_id, corners))\n",
        "\n",
        "    return decoded_markers\n",
        "\n",
        "def extract_id_from_image(marker_image, grid_size):\n",
        "    cell_size = marker_image.shape[0] // grid_size\n",
        "    id_bits = []\n",
        "\n",
        "    for y in range(0, marker_image.shape[0], cell_size):\n",
        "        for x in range(0, marker_image.shape[1], cell_size):\n",
        "            cell = marker_image[y:y+cell_size, x:x+cell_size]\n",
        "            id_bit = int(np.mean(cell) > 127)\n",
        "            id_bits.append(id_bit)\n",
        "\n",
        "    return id_bits\n",
        "\n",
        "def bits_to_id(bits):\n",
        "    id = 0\n",
        "    for bit in bits:\n",
        "        id = (id << 1) | bit\n",
        "    return id\n",
        "\n",
        "min_area_percentage = 0.01\n",
        "max_area_percentage = 0.1\n",
        "\n",
        "# Example usage\n",
        "image_path = 'test.jpg'\n",
        "thresh_image, gray_image = preprocess_image(image_path)\n",
        "image_area = thresh_image.shape[0] * thresh_image.shape[1]\n",
        "minimum_area_threshold = min_area_percentage * image_area\n",
        "maximum_area_threshold = max_area_percentage * image_area\n",
        "\n",
        "potential_markers = detect_potential_markers(thresh_image)\n",
        "refined_markers = refine_corners(potential_markers, gray_image)\n",
        "decoded_markers = decode_marker(gray_image, refined_markers)\n",
        "\n",
        "for marker_id, corners in decoded_markers:\n",
        "    print(f\"Decoded marker ID: {marker_id}\")\n",
        "    corners = np.int0(corners)\n",
        "    cv2.polylines(thresh_image, [corners], True, (0, 255, 0), 2)\n",
        "\n",
        "cv2_imshow(thresh_image)\n",
        "\n",
        "for marker_id, corners in decoded_markers:\n",
        "    print(f\"Decoded marker ID: {marker_id}\")\n",
        "\n",
        "    int_corners = np.int0(corners)\n",
        "\n",
        "    cv2.polylines(thresh_image, [int_corners], True, (0, 255, 0), 2)\n",
        "\n",
        "cv2_imshow(thresh_image)\n"
      ],
      "metadata": {
        "id": "FYI9N96mTemy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "image_path = 'singlemarkersoriginal.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "image_area = image.shape[0] * image.shape[1]\n",
        "\n",
        "marker_width_estimate = image.shape[1] / 20\n",
        "marker_area_estimate = marker_width_estimate**2\n",
        "\n",
        "min_area_factor = 0.5\n",
        "max_area_factor = 1.5\n",
        "minimum_area_threshold = min_area_factor * marker_area_estimate\n",
        "maximum_area_threshold = max_area_factor * marker_area_estimate\n",
        "\n",
        "print(f\"Estimated marker area: {marker_area_estimate}\")\n",
        "print(f\"Minimum area threshold: {minimum_area_threshold}\")\n",
        "print(f\"Maximum area threshold: {maximum_area_threshold}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pteckj7-VUyl",
        "outputId": "7db88678-3cec-4b06-8781-3a5113acb59e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated marker area: 1024.0\n",
            "Minimum area threshold: 512.0\n",
            "Maximum area threshold: 1536.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    _, thresh = cv2.threshold(blurred, 125, 255, cv2.THRESH_BINARY_INV)\n",
        "    return thresh, gray\n",
        "\n",
        "def detect_potential_markers(thresh_image):\n",
        "    contours, _ = cv2.findContours(thresh_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    potential_markers = []\n",
        "    for contour in contours:\n",
        "        perimeter = cv2.arcLength(contour, True)\n",
        "        approx = cv2.approxPolyDP(contour, 0.04 * perimeter, True)\n",
        "        if len(approx) == 4:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if minimum_area_threshold < area < maximum_area_threshold:\n",
        "                potential_markers.append(approx)\n",
        "    return potential_markers\n",
        "\n",
        "def refine_corners(potential_markers, gray_image):\n",
        "    refined_markers = []\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
        "    for contour in potential_markers:\n",
        "        corners = np.float32(contour).reshape(-1, 2)\n",
        "        cv2.cornerSubPix(gray_image, corners, (5, 5), (-1, -1), criteria)\n",
        "        refined_markers.append(corners)\n",
        "    return refined_markers\n",
        "\n",
        "image_path = 'test.jpg'\n",
        "thresh_image, gray_image = preprocess_image(image_path)\n",
        "image_area = thresh_image.shape[0] * thresh_image.shape[1]\n",
        "\n",
        "minimum_area_threshold = image_area / 2 * 0.8\n",
        "maximum_area_threshold = image_area / 2 * 1.2\n",
        "\n",
        "print(f\"Minimum area threshold: {minimum_area_threshold}\")\n",
        "print(f\"Maximum area threshold: {maximum_area_threshold}\")\n",
        "\n",
        "potential_markers = detect_potential_markers(thresh_image)\n",
        "print(f\"Detected {len(potential_markers)} potential markers.\")\n",
        "\n",
        "refined_markers = refine_corners(potential_markers, gray_image)\n",
        "print(f\"Refined {len(refined_markers)} potential markers.\")\n",
        "\n",
        "for corners in refined_markers:\n",
        "    int_corners = np.int0(corners)\n",
        "    cv2.polylines(thresh_image, [int_corners], True, (0, 255, 0), 2)\n",
        "\n",
        "cv2_imshow(thresh_image)\n"
      ],
      "metadata": {
        "id": "anc2U4VnXYMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    _, thresh = cv2.threshold(blurred, 125, 255, cv2.THRESH_BINARY_INV)\n",
        "    return thresh, gray\n",
        "\n",
        "def detect_potential_markers(thresh_image):\n",
        "    contours, _ = cv2.findContours(thresh_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    potential_markers = []\n",
        "    for contour in contours:\n",
        "        perimeter = cv2.arcLength(contour, True)\n",
        "        approx = cv2.approxPolyDP(contour, 0.04 * perimeter, True)\n",
        "        if len(approx) == 4:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if minimum_area_threshold < area < maximum_area_threshold:\n",
        "                potential_markers.append(approx)\n",
        "    return potential_markers\n",
        "\n",
        "def refine_corners(potential_markers, gray_image):\n",
        "    refined_markers = []\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
        "    for contour in potential_markers:\n",
        "        corners = np.float32(contour).reshape(-1, 2)\n",
        "        cv2.cornerSubPix(gray_image, corners, (5, 5), (-1, -1), criteria)\n",
        "        refined_markers.append(corners)\n",
        "    return refined_markers\n",
        "\n",
        "image_path = 'test.jpg'\n",
        "thresh_image, gray_image = preprocess_image(image_path)\n",
        "\n",
        "image_area = gray_image.shape[0] * gray_image.shape[1]\n",
        "minimum_area_threshold = image_area * 0.25\n",
        "maximum_area_threshold = image_area * 0.75\n",
        "\n",
        "print(f\"Minimum area threshold: {minimum_area_threshold}\")\n",
        "print(f\"Maximum area threshold: {maximum_area_threshold}\")\n",
        "\n",
        "potential_markers = detect_potential_markers(thresh_image)\n",
        "print(f\"Detected {len(potential_markers)} potential markers.\")\n",
        "\n",
        "refined_markers = refine_corners(potential_markers, gray_image)\n",
        "print(f\"Refined {len(refined_markers)} potential markers.\")\n",
        "\n",
        "for corners in refined_markers:\n",
        "    int_corners = np.int0(corners)\n",
        "    cv2.polylines(thresh_image, [int_corners], True, (0, 255, 0), 2)\n",
        "\n",
        "cv2_imshow(thresh_image)\n"
      ],
      "metadata": {
        "id": "xwF7igNtXykN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}